# Machine Learning Platform with MLflow

## Project Overview
This Machine Learning Platform is designed as a template for training, tuning, and serving machine learning models using Docker containers. For the focus is on experimentation and running workloads from your local machine. The project leverages the open-source [MLflow framework](https://mlflow.org/docs/latest/index.html) for managing the machine learning lifecycle, including experimentation, reproducibility, and deployment.

## Features
- **Automation**: Leverages Bash scripts to streamline the definition of variables and execution of ML workflows, automatically select predefined scikit-learn models and text vectorizers.
- **MLflow Integration**: Utilizes MLflow for managing the machine learning lifecycle, including experimentation, reproducibility, and deployment.
- **Parameter Tuning at Scale**: MLflow runs are submitted as seperate tasks to the ProcessPoolExecutor. Since each task is run in a separate process, they can execute in parallel.
- **Dockerized Components**: Separate Docker containers for model training, parameter tuning, and serving the model, ensuring modularity and scalability.
- **Logging System**: logging for visibility across running services
- **Error Handling**: custom defined exceptions for identifying where code breaks
- **Dataset Structure**: The dataset consists of two columns - 'text' (student feedback) and 'labels' (sentiment labels). Some data was generated by ChatGPT and some was found here: https://github.com/gautamgc17/Student-Feedback-Sentiment-Analysis/blob/main/feedback1.json


### Prerequisites
Be sure to have installed the following on your machine.
- Python 3.x
- Docker
- MLflow

Also run:
```sh pip install requirements.txt```


### ML Workloads
There are three primary workloads we can execute:
1. Parameter Tuning: running multiple mlflow runs in parallel and selecting the best result
2. Model Training: running model training
3. Deployment and Inference: serving the model to make predictions

When running training or tune jobs specifying one of the following names to select your model and tokenizer.

Currently you can train the following scikit-learn models:
| **Algorithm** | **Model Name at Runtime** |
|:-----------:|:-----:|
|Multinomial Naive Bayes|nb|
|Support Vector Classifier|svc|
|Random Forest Classifier|rf|
|Logistic Regression|lr|

You can also select one of the two following vectorizers as a tokenizer:
| **Algorithm** | **Model Name at Runtime** |
|:-----------:|:-----:|
|Count Vectorizer|count|
|TF-IDF Vectorizer|tfidf|


### How to Run ML Workloads
1. Docker Containers (Recommended): run workloads as isolated snapshots of your code
2. Command-line: run the scripts directly from the console

The following Variables should be set to run any of the workloads:
| **Parameter** | **Description** |
|:-----------|:-----|
|Tracking URI|URI for the MLFlow tracking server ex: http://localhost:7000|
|Experiment Name|Name of experiment you want to run your workload under|
|Run Name|Name of the current MLFlow run|
|Model Name|One of the specified model names in models.py (nb, svc, rf, lr)|
|Tokenizer Name| One of the specified tokenizers (count or tfidf) in models.py|

### 00 - Getting Started - Run the MLflow Server
In order to run any ml workloads, we need to first have an mlflow server running where can can access  and visualize our experiments, runs, artifacts, metrics, and more.
Run the folllowing to command to start the mlflow tracking UI on your local machine:
```
mlflow server --host=$MLFLOW_SERVER_HOST --port=$MLFLOW_SERVER_PORT --serve-artifacts
```
Be sure to use your IP address as the host server so that your docker containers can communicate with the MLflow tracking server. You can print your local IP with the following command:
```sh
ifconfig | grep inet
```
Navigate to your MLFLOW_SERVER_HOST:PORT to checkout the UI.

### 01 - Getting Started - Running with Docker
1. **Clone the Repository**
   ```sh
   git clone https://github.com/tristanoprofetto/ml-platform
   ```

2. **Define Environment Variables**
   Navigate to the automation folder and define the required environment variables in ./automation/variables.sh


3. **Run ML Workflows**
   Execute training, tuning, or deployment jobs by executing any of these commands
   * Model Training:
   ```sh
   bash ./automation/execute.sh train
   ```
   * Parameter Tuning:
   ```sh
   bash ./automation/execute.sh tune
   ```
   * Deploy
   ```sh
   bash ./automation/execute.sh deploy
   ```
   * End-to-End (coming soon)

### 02 - Getting Started - Executing Scripts Locally
##### Finding the best Model Parameters
1. Run parameter tuning directly:
```sh
python3 ./steps/tune.py \
--tracking_uri=$MLFLOW_TRACKING_URI \
--experiment_name=$MLFLOW_EXPERIMENT_NAME \
--run_name=$MLFLOW_RUN_NAME \
--model_name=$MODEL_NAME \
--tokenizer_name=$TOKENIZER_NAME
```
2. Navigate to MLFlow Server Check and Compare MLFlow runs through the Tracking UI

##### Training the Model
1. Set model, tokenizer, and data parameters for running the training job in the conf.ini file.
2. Run the training script.
   ```sh
   python ./steps/train.py \
   --tracking_uri=$MLFLOW_TRACKING_URI \
   --experiment_name=$MLFLOW_EXPERIMENT_NAME \
   --run_name=$MLFLOW_RUN_NAME \
   --model_name=$MODEL_NAME \
   --tokenizer_name=$TOKENIZER_NAME
   ```
3. Navigate to the MLFlow Tracking UI to visualize results

##### Serving the Model
1. Make sure to copy the run_id for the specific model you want to deploy
2. Build the docker image by running:
   ```sh
   docker build -t $SERVE_IMAGE_TAG -f ./dockerfiles/serve/Dockerfile .
   ```
3. Run the container:
   ```sh
   docker run -p 8000:8000 -e TRACKING_URI=$MLFLOW_TRACKING_URI -e RUN_ID=$SERVE_RUN_ID $SERVE_IMAGE_TAG
   ```
4. Run the predict.py script to make inferences on the running container. Add your own inputs you want to test.

## High-Level System Architecture (ideally)
1. UI Layer: MLFlow tracking UI for visualizing and comparing experiments, registered models, runs, artifacts, metrics and more.
2. Application Layer: for managing the orchestration of ML workloads and networking between services.
3. Data Layer: manages data for running ML workloads
4. Logging and Monitoring: ensures visiblity of health and performance across services
5. Testing: ensures reliability and functionality of system components and their interactions

## Additional Considerations
1. Scalability: connecting to cloud platforms for handling larger datasets, and running more intensive workloads.
2. Security: implement robust security measures, especially when handling sensitive datasets.
3. CI/CD: automate the testing and deployment of services in a production environment.
4. Documentation and Support: write more comprehensive documentation and potentially support channels.

### Code Structure
Here is a quick breakdown of the code structure
* automation: automate the execution of ML workflows with bash scripts
* data: sample dataset for running training and tuning
* dockerfiles: required dockerfiles for building the images
* exceptions: custom defined exceptions for better error handling
* logger: custom Python logger
* steps: the required modules that execute our machine learning workflows
* tests: functional testing
* app.py: model server file
* models.py: set of models to select for training or tuning
* params.py: set of parameters for training or tuning

